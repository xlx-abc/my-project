# %%
# load data
import pandas as pd

data = pd.read_csv('data//train.csv')
df= data.copy()
df.sample(10)
# %%
# delete some features that are not useful for prediction
df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)
df.info()
# %%
# check if there is any NaN in the dataset
print('Is there any NaN in the dataset: {}'.format(df.isnull().values.any()))
df.dropna(inplace=True)
print('Is there any NaN in the dataset: {}'.format(df.isnull().values.any()))
# %%
# convert categorical data into numerical data using one-hot encoding
# For example, a feature like sex with categories ['male', 'female'] would be transformed into two new binary features, sex_male and sex_female, represented by 0 and 1.
df = pd.get_dummies(df)
df.sample(10)
# %% 
# separate the features and labels
y=df['Survived']
X=df.iloc[:,2:]

# %%
# train-test split
import numpy as np
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
print('X_train: {}'.format(np.shape(X_train)))
print('y_train: {}'.format(np.shape(y_train)))
print('X_test: {}'.format(np.shape(X_test)))
print('y_test: {}'.format(np.shape(y_test)))

# %%
# build model
# build three classification models
# SVM, KNN, Random Forest
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)
print('Model intercept: ', reg.intercept_)
print('Model coefficients: ', reg.coef_)
print('y = {} + {} * X1 + {} * X2 + {} * X3 + {} * X4 + {} * X5'.format(reg.intercept_, reg.coef_[0], reg.coef_[1], reg.coef_[2], reg.coef_[3], reg.coef_[4]))
# %%
# predict and evaluate
from sklearn.metrics import r2_score

r2_score(y_train, reg.predict(X_train))
from sklearn.model_selection import cross_val_score
print(cross_val_score(reg, X_train, y_train, cv=10, scoring='r2'))
cross_val_score(reg, X_train, y_train, cv=10, scoring='r2').mean()
y_pred = reg.predict(X_test)
r2_score(y_test, y_pred)
